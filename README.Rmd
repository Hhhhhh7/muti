---
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(muti)
```

# muti

`muti` is an `R` package that computes the mutual information (MI) between two discrete random variables _X_ and _Y_. `muti` was developed with time series analysis in mind, but there is nothing tying the methods to a time index _per se_.

You can install the development version using `devtools`.

```
if(!require("devtools")) {
  install.packages("devtools")
  library("devtools")
}
devtools::install_github("mdscheuerell/muti")
```

## Background

MI estimates the amount of information about one variable contained in another; it can be thought of as a nonparametric measure of the covariance between the two variables. MI is a function of entropy, which is the expected amount of information contained in a variable. If _P_(_X_) is the probability mass function of _X_, then the entropy of _X_ is

_H_(_X_) = E[-ln(P(X))].

The MI between _X_ and _Y_ is then

MI(_X_,_Y_) = _H_(_X_) + _H_(_Y_) - _H_(_X_,_Y_)

where _H_(_X_,_Y_) is the joint entropy between _X_ and _Y_. `muti` uses base-2 logarithms for calculating the entropies, so MI measures information content in units of "bits".

## Data discretization

`muti` computes MI based on 1 of 2 possible discretizations of the data:

1. __Symbolic__. In this case the _i_-th datum is converted to 1 of 5 symbolic representations (_i.e._, "peak", "decreasing", "same", "trough", "increasing") based on its value relative to the _i_-1 and _i_+1 values (see [Cazelles 2004](https://doi.org/10.1111/j.1461-0248.2004.00629.x) for details). Thus, the resulting symbolic vector is 2 values shorter than its original vector. For example, if the original vector was `c(1.2,2.1,3.3,1.1,3.1,2.2)`, then its symbolic vector for values 2-5 would be `c("increasing","peak","trough","peak")`.

2. __Binned__. In this case each datum is placed into 1 of _n_ equally spaced bins. If the number of bins is not specified, then it is calculated according to Rice's Rule whereby `n = ceiling(2*length(x)^(1/3))`.

## I/O

At a minimum `muti` requires two vectors of class `numeric` or `integer`. See `?muti` for all of the other function arguments.

The output of `muti` is a data frame with the MI `MI_xy` and respective significance threshold value `MI_tv` at different lags. Additionally, `muti` produces plots of the original data (top), discretized data (middle), and the MI values (solid line) and associated threshold values (dashed line) at different lags (bottom). The significance thresholds are based on bootstraps of the original data. That process is relatively slow, so please be patient if asking for more than the default `mc=100` samples.

## Examples

### Ex 1: Real values as symbolic

Here's an example with significant correlation between two numeric vectors. Notice that none of the symbolic values are the "same".

```{r ex_1, fig.width=6, fig.height=8, warning=FALSE}
set.seed(123)
TT <- 30
x1 <- rnorm(TT)
y1 <- x1 + rnorm(TT)
muti(x1,y1)
```

### Ex 2: Integer values as symbolic

Here's an example with significant correlation between two integer vectors.

```{r ex_2, fig.width=6, fig.height=8, warning=FALSE}
x2 <- rpois(TT,4)
y2 <- x2 + sample(c(-1,1),TT,replace=TRUE)
muti(x2,y2)
```

### Ex 3: Real values as symbolic with normalized MI

Same as Ex 1 with MI normalized to [0,1]. In this case MI'(_X_,_Y_) = MI(_X_,_Y_)/sqrt(_H_(_X_)*_H_(_Y_)).

```{r ex_3, fig.width=6, fig.height=8, warning=FALSE}
muti(x1,y1,normal=TRUE)
```

### Ex 4: Real values with binning

Same as Ex 1 with regular binning instead of symbolic.

```{r ex_4, fig.width=6, fig.height=8, warning=FALSE}
muti(x1,y1,sym=FALSE)
```

### Ex 5: Autocorrelation

Here's an example of examining the MI of a single time series at multiple time lags.

```{r ex_5, fig.width=6, fig.height=8, warning=FALSE}
x3 <- cumsum(rnorm(TT))
muti(x3,x3,sym=FALSE)
```

