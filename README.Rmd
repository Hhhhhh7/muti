---
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(muti)
```

# muti

`muti` is an `R` package that computes the mutual information (MI) between two discrete random variables _X_ and _Y_. `muti` was developed with time series analysis in mind, but there is nothing tying the methods to a time index _per se_.

[![DOI](https://zenodo.org/badge/85351399.svg)](https://zenodo.org/badge/latestdoi/85351399)

## Installation

You can install the development version using `devtools`.

```
if(!require("devtools")) {
  install.packages("devtools")
  library("devtools")
}
devtools::install_github("mdscheuerell/muti")
```

## Background

MI estimates the amount of information about one variable contained in another; it can be thought of as a nonparametric measure of the covariance between the two variables. MI is a function of entropy, which is the expected amount of information contained in a variable. If _P_(_X_) is the probability mass function of _X_, then the entropy of _X_ is

_H_(_X_) = E[-ln(P(X))].

The MI between _X_ and _Y_ is then

MI(_X_,_Y_) = _H_(_X_) + _H_(_Y_) - _H_(_X_,_Y_)

where _H_(_X_,_Y_) is the joint entropy between _X_ and _Y_. `muti` uses base-2 logarithms for calculating the entropies, so MI measures information content in units of "bits".

## Data discretization

`muti` computes MI based on 1 of 2 possible discretizations of the data:

1. __Symbolic__. In this case the _i_-th datum is converted to 1 of 5 symbolic representations (_i.e._, "peak", "decreasing", "same", "trough", "increasing") based on its value relative to the _i_-1 and _i_+1 values (see [Cazelles 2004](https://doi.org/10.1111/j.1461-0248.2004.00629.x) for details). Thus, the first and last values are undefined and the resulting symbolic vector is 2 values shorter than its original vector. For example, if the original vector was `c(1.1,2.1,3.3,1.2,3.1)`, then its symbolic vector would be `c("increasing","peak","trough")`.

2. __Binned__. In this case each datum is placed into 1 of _n_ equally spaced bins. If the number of bins is not specified, then it is calculated according to Rice's Rule whereby for vectors `x` and `y` of length `L`, `n = ceiling(2*L^(1/3))`.

## I/O

__Input__. At a minimum `muti` requires two vectors of class `numeric` or `integer`. See `?muti` for all of the other function arguments.

__Output__. The output of `muti` is a data frame with the MI `MI_xy` and respective significance threshold value `MI_tv` at different lags. Note that a negative (positive) lag means _X_ leads (trails) _Y_. For example, if comparing vectors `x` and `y` that were both `TT` units long, then the MI at a lag of -1 would be based on `x[1:(TT-1)]` and `y[2:TT]`.

Additionally, `muti` produces 3 plots of

1. the original data (top);
2. their symbolic or discretized form (middle);
3. MI values (solid line) and their associated threshold values (dashed line) at different lags (bottom).

The significance thresholds are based on bootstraps of the original data. That process is relatively slow, so please be patient if asking for more than the default `mc=100` samples.

## Examples

### Ex 1: Real values as symbolic

Here's an example with significant information between two numeric vectors. Notice that none of the symbolic values are the "same".

```{r ex_1, fig.width=6, fig.height=8, warning=FALSE}
set.seed(123)
TT <- 30
x1 <- rnorm(TT)
y1 <- x1 + rnorm(TT)
muti(x1, y1)
```

### Ex 2: Integer values as symbolic

Here's an example with significant information between two integer vectors. Notice that in this case some of the symbolic values are the "same".

```{r ex_2, fig.width=6, fig.height=8, warning=FALSE}
x2 <- rpois(TT,4)
y2 <- x2 + sample(c(-1,1), TT, replace = TRUE)
muti(x2, y2)
```

### Ex 3: Real values as symbolic with normalized MI

Here are the same data as Ex 1 but with MI normalized to [0,1] (`normal = TRUE`). In this case MI'(_X_,_Y_) = MI(_X_,_Y_)/sqrt(_H_(_X_)*_H_(_Y_)) and the units are dimensionless.

```{r ex_3, fig.width=6, fig.height=8, warning=FALSE}
muti(x1, y1, normal = TRUE)
```

### Ex 4: Real values with binning

Here are the same data as Ex 1 but with regular binning instead of symbolic (`sym = FALSE`).

```{r ex_4, fig.width=6, fig.height=8, warning=FALSE}
muti(x1, y1, sym = FALSE)
```

### Ex 5: Auto-information

Here's an example of examining the normalized MI of a single time series at various time lags.

```{r ex_5, fig.width=6, fig.height=8, warning=FALSE}
x3 <- cumsum(rnorm(TT))
muti(x3, x3, sym = FALSE, normal = TRUE)
```

